# **Crawler â€“ High-Performance Web Crawler**

ðŸ“Œ **Efficient, Concurrent, and Scalable Web Scraper built with Go**

[![Go Version](https://img.shields.io/badge/Go-1.20%2B-blue)](https://golang.org/)  
[![License](https://img.shields.io/github/license/NesterovYehor/Crawler)](LICENSE)  

---

## **ðŸ“– Overview**
**Crawler** is a high-performance web scraping tool written in **Go**, leveraging **goroutines, channels, and mutexes** for efficient, concurrent crawling. It extracts **URLs, text, and metadata** from web pages while maintaining rate limits and error resilience.

---

## **ðŸš€ Features**
âœ… **Concurrent Crawling** â€“ Uses **goroutines & channels** to fetch multiple pages at once.  
âœ… **Efficient URL Parsing** â€“ Extracts and normalizes links using [`golang.org/x/net/html`](https://pkg.go.dev/golang.org/x/net/html).  
âœ… **Rate-Limiting & Throttling** â€“ Avoids overwhelming target servers.  
âœ… **Resilient Error Handling** â€“ Retries failed requests intelligently.  

---

## **ðŸ“¦ Installation**
Make sure you have **Go 1.20+** installed. Then, clone the repository and build the project:

```sh
# Clone the repository
git clone https://github.com/NesterovYehor/Crawler.git
cd Crawler

# Build the project
go build -o crawler main.go
```

---

## **ðŸ›  Usage**
Run the crawler with a starting URL:

```sh
./crawler -url=https://example.com -depth=2
```

### **Command-Line Options:**
| Flag            | Description                                   |
|----------------|-----------------------------------------------|
| `-url`        | The starting URL for crawling                 |
| `-depth`      | Maximum depth for recursive crawling          |
| `-workers`    | Number of concurrent workers                  |
| `-timeout`    | Timeout for HTTP requests (in seconds)        |


---

## **ðŸ“œ License**
This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

---

## **ðŸ“¬ Contact**
ðŸ‘¤ **Yehor Nesterov**  
ðŸ“§ yehorn38@gmail.com  
ðŸ“Œ [GitHub](https://github.com/NesterovYehor)  

---

ðŸš€ **Happy Crawling!**
